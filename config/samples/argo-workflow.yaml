apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: argo-test-01
spec:
  entrypoint: pi-tmpl
  serviceAccountName: spark-operator
  templates:
  - name: pi-tmpl
    resource:                   # indicates that this is a resource template
      action: create            # can be any kubectl action (e.g. create, delete, apply, patch)
      # The successCondition and failureCondition are optional expressions.
      # If failureCondition is true, the step is considered failed.
      # If successCondition is true, the step is considered successful.
      # They use kubernetes label selection syntax and can be applied against any field
      # of the resource (not just labels). Multiple AND conditions can be represented by comma
      # delimited expressions.
      # For more details: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
      successCondition: status.succeeded > 0
      failureCondition: status.failed > 3
      manifest: |               #put your kubernetes spec here
        apiVersion: "sparkoperator.k8s.io/v1beta2"
        kind: SparkApplication
        metadata:
          generateName: pi-job-
        spec:
          type: Python
          pythonVersion: "3"
          mode: cluster
          image: "gcr.io/spark-operator/spark-py:v3.1.1"
          imagePullPolicy: Always
          mainApplicationFile: local:///opt/spark/examples/src/main/python/pi.py
          sparkVersion: "3.1.1"
          restartPolicy:
            type: OnFailure
            onFailureRetries: 3
            onFailureRetryInterval: 10
            onSubmissionFailureRetries: 5
            onSubmissionFailureRetryInterval: 20
          driver:
            cores: {{ index .driver "cores" }}
            coreLimit: "1200m"
            memory: "512m"
            labels:
              version: 3.1.1
            serviceAccount: spark
          executor:
            cores: 1
            instances: 1
            memory: "512m"
            labels:
              version: 3.1.1
